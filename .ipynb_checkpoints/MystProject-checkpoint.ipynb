{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.cluster import KMeans\n",
    "from pyearth import Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = \"darkgrid\")\n",
    "\n",
    "fig_path = '../Figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('myst_ai_load_exercise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'Unnamed: 0':'datetime'}, inplace = True)\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('datetime', drop = False)\n",
    "del data.index.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(date = data.index.date)\n",
    "data = data.assign(hour = data.index.hour)\n",
    "data = data.assign(weekday_name = data.index.weekday_name)\n",
    "data = data.assign(weekday = data.index.weekday)\n",
    "print data.dtypes\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 1.0 / 3.0\n",
    "validateSize = 1.0 / 3.0\n",
    "\n",
    "testStart = int(round((1-testSize)*len(data)))\n",
    "test = data.iloc[testStart:len(data)]\n",
    "\n",
    "validateStart = int(round((1-validateSize)*testStart))\n",
    "validate = data.iloc[validateStart:testStart]\n",
    "\n",
    "train = data.iloc[0:validateStart]\n",
    "\n",
    "print \"data start: \" + str(data.datetime.min())\n",
    "print \"train start: \" + str(train.datetime.min())\n",
    "print \"train end: \" + str(train.datetime.max())\n",
    "print \"validate start: \" + str(validate.datetime.min())\n",
    "print \"validate end: \" + str(validate.datetime.max())\n",
    "print \"test start: \" + str(test.datetime.min())\n",
    "print \"test end: \" + str(test.datetime.max())\n",
    "print \"data end: \" + str(data.datetime.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Daily Maximum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load1 = train.rename(columns = {'load_1':'load'}).drop(columns=['load_2'])\n",
    "load2 = train.rename(columns = {'load_2':'load'}).drop(columns=['load_1'])\n",
    "\n",
    "dailyMax1 = load1.loc[load1.groupby(['date'])['load'].idxmax()]\n",
    "dailyMax2 = load2.loc[load2.groupby(['date'])['load'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2014-1':'2014-6'])\n",
    "f1.suptitle('Load 1: 01/2014 - 06/2014')\n",
    "ax1.set(ylim = (15, 105))\n",
    "f1.savefig(fig_path + \"Load_1 ts1.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2014-7':'2014-12'])\n",
    "f1.suptitle('Load 1: 07/2014 - 12/2014')\n",
    "ax1.set(ylim = (15, 105))\n",
    "f1.savefig(fig_path + \"Load_1 ts2.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2015-1':'2015-6'])\n",
    "f1.suptitle('Load 1: 01/2015 - 06/2015')\n",
    "ax1.set(ylim = (15, 105))\n",
    "f1.savefig(fig_path + \"Load_1 ts3.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2015-7':'2015-12'])\n",
    "f1.suptitle('Load 1: 07/2015 - 12/2015')\n",
    "ax1.set(ylim = (15, 105))\n",
    "f1.savefig(fig_path + \"Load_1 ts4.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2016-1':'2016-6'])\n",
    "f1.suptitle('Load 1: 01/2016 - 02/2016')\n",
    "ax1.set(ylim = (15, 105))\n",
    "f1.savefig(fig_path + \"Load_1 ts5.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2014-1':'2014-6'])\n",
    "f1.suptitle('Load 2: 01/2014 - 06/2014')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_2 ts1.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2014-7':'2014-12'])\n",
    "f1.suptitle('Load 2: 07/2014 - 12/2014')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_2 ts2.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2015-1':'2015-6'])\n",
    "f1.suptitle('Load 2: 01/2015 - 06/2015')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_2 ts3.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2015-7':'2015-12'])\n",
    "f1.suptitle('Load 2: 07/2015 - 12/2015')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_2 ts4.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2016-1':'2016-6'])\n",
    "f1.suptitle('Load 2: 01/2016 - 02/2016')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_2 ts5.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2015-03-25'\n",
    "end = '2015-04-15'\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train[start:end])\n",
    "f1.suptitle('Load 1')\n",
    "f1.savefig(fig_path + 'Load_1 sample weeks.png', dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train[start:end])\n",
    "f1.suptitle('Load 2')\n",
    "f1.savefig(fig_path + 'Load_2 sample weeks.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summer Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2, ax2 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x ='datetime', y = 'load_2', data=train['2015-06-25':'2015-08-10'])\n",
    "f2.suptitle('Load 2 Structure Change')\n",
    "f2.savefig(fig_path + 'Load_2 Noise Big.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2, ax2 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x ='datetime', y = 'load_2', data=train['2015-07-01':'2015-07-14'])\n",
    "f2.suptitle('Load 2 Structure Change')\n",
    "f2.savefig(fig_path + \"Load_2 Noise Small.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.violinplot(x=train.load_1)\n",
    "f1.suptitle('Load 1 Violin Plot', fontsize=16)\n",
    "\n",
    "f2, ax2 = plt.subplots(figsize=(14, 8))\n",
    "sns.violinplot(x=train.load_2)\n",
    "f2.suptitle('Load 2 Violin Plot', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Max Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.violinplot(x=dailyMax1['load'])\n",
    "f1.suptitle('Load 1 Daily Max Violin Plot', fontsize=16)\n",
    "\n",
    "f2, ax2 = plt.subplots(figsize=(14, 8))\n",
    "sns.violinplot(x=dailyMax2['load'])\n",
    "f2.suptitle('Load 2 Daily Max Violin Plot', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Max vs. Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(data = dailyMax1, x = 'temp', y = 'load')\n",
    "f1.suptitle('Load 1 Daily Max vs. Temperature')\n",
    "f1.savefig(fig_path + \"Load_1 Daily Max vs Temp.png\", dpi=300)\n",
    "\n",
    "f2, ax2 = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(data = dailyMax2, x = 'temp', y = 'load')\n",
    "f2.suptitle('Load 2 Daily Max vs. Temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facet Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter_days(x):\n",
    "    if x<6:\n",
    "        return '00:00 - 06:00'\n",
    "    elif x<12:\n",
    "        return '06:00 - 12:00'\n",
    "    elif x<18:\n",
    "        return '12:00 - 18:00'\n",
    "    else:\n",
    "        return '18:00 - 00:00'\n",
    "    \n",
    "def adjust_hours(x):\n",
    "    if x in [0, 6, 12, 18]:\n",
    "        return 'zero'\n",
    "    elif x in [1, 7, 13, 19]:\n",
    "        return 'one'\n",
    "    elif x in [2, 8, 14, 20]:\n",
    "        return 'two'\n",
    "    elif x in [3, 9, 15, 21]:\n",
    "        return 'three'\n",
    "    elif x in [4, 10, 16, 22]:\n",
    "        return 'four'\n",
    "    else:\n",
    "        return 'five'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load1_temp = load1.assign(quarter = load1.hour.apply(quarter_days))\n",
    "load2_temp = load2.assign(quarter = load2.hour.apply(quarter_days))\n",
    "\n",
    "load1_temp = load1_temp.assign(hour = load1_temp.hour.apply(adjust_hours))\n",
    "load2_temp = load2_temp.assign(hour = load2_temp.hour.apply(adjust_hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(data=load1_temp, x=\"temp\", y=\"load\", hue='hour', col='quarter', \\\n",
    "                  col_wrap = 2, height=8, aspect = 0.67)\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Load 1 Facets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(data=load1_temp, x=\"temp\", y=\"load\", hue='hour', row = 'weekday_name', \\\n",
    "                col='quarter', height=16, aspect = 0.67)\n",
    "g.fig.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Load 1 Facets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(data=load2_temp['2014-08-10':'2015-06-25'], x=\"temp\", y=\"load\", hue='hour', col='quarter', \\\n",
    "                  col_wrap = 2, height=8, aspect = 0.67)\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Load 2 Facets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(data=load2_temp['2014-08-10':'2015-06-25'], x=\"temp\", y=\"load\", hue='hour', row = 'weekday', \\\n",
    "                col='quarter', height=8, aspect = 0.67)\n",
    "g.fig.subplots_adjust(top=0.95)\n",
    "g.fig.suptitle('Load 2 Facets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(data = load1[(load1['weekday'] == 3) & (load1['hour'] == 18)]['2014-08-10':'2015-06-25'], \\\n",
    "                x = 'date', y = 'load', ax=ax1)\n",
    "sns.lineplot(data = load1[(load1['weekday'] == 3) & (load1['hour'] == 18)]['2014-08-10':'2015-06-25'], \\\n",
    "                x = 'date', y = 'temp', ax=ax2, color='r')\n",
    "f1.suptitle('Load 1')\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.scatterplot(data = load1[(load1['weekday'] == 3) & (load1['hour'] == 18)]['2014-08-10':'2015-06-25'], \\\n",
    "                x = 'temp', y = 'load')\n",
    "f1.suptitle('Load 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "ax2 = ax1.twinx()\n",
    "sns.lineplot(data = load2[(load2['weekday'] == 3) & (load2['hour'] == 18)]['2014-08-10':'2015-06-25'], \\\n",
    "                x = 'date', y = 'load', ax=ax1, label='Load', legend=False)\n",
    "sns.lineplot(data = load2[(load2['weekday'] == 3) & (load2['hour'] == 18)]['2014-08-10':'2015-06-25'], \\\n",
    "                x = 'date', y = 'temp', ax=ax2, color='r', label='Temp', legend=False)\n",
    "f1.legend()\n",
    "f1.suptitle('Load 2: Temperature and Load Time Series')\n",
    "f1.savefig(fig_path + \"Load_2 load_temp ts.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load1_days = load1[['date', 'load']]\n",
    "load1_days = load1_days.assign(hour = load1_days.index.hour)\n",
    "load1_days = load1_days.pivot(index = 'date', columns = 'hour', values = 'load')\n",
    "load1_days = load1_days.dropna()\n",
    "\n",
    "load2_days = load2[['date', 'load']]\n",
    "load2_days = load2_days.assign(hour = load2_days.index.hour)\n",
    "load2_days = load2_days.pivot(index = 'date', columns = 'hour', values = 'load')\n",
    "load2_days = load2_days.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1 = KMeans(n_clusters = 4, n_init = 50, max_iter = 500).fit(load1_days)\n",
    "kmeans2 = KMeans(n_clusters = 5, n_init = 50, max_iter = 500).fit(load2_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_clusters(x):\n",
    "    lookup = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H'}\n",
    "    return lookup[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans1_centers = pd.DataFrame(kmeans1.cluster_centers_).reset_index().rename(columns={'index':'cluster'})\n",
    "kmeans1_centers = pd.melt(kmeans1_centers, id_vars = ['cluster'], value_vars = list(kmeans1_centers)[1:], \\\n",
    "       var_name = 'hour', value_name = 'load')\n",
    "kmeans1_centers['hour'] = kmeans1_centers['hour'].astype('float')\n",
    "kmeans1_centers['cluster'] = kmeans1_centers.cluster.apply(convert_clusters)\n",
    "kmeans1_centers['cluster'] = kmeans1_centers.cluster.astype('category')\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.lineplot(data=kmeans1_centers, x='hour', y='load', hue='cluster')\n",
    "f1.suptitle('Load 1 Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans2_centers = pd.DataFrame(kmeans2.cluster_centers_).reset_index().rename(columns={'index':'cluster'})\n",
    "kmeans2_centers = pd.melt(kmeans2_centers, id_vars = ['cluster'], value_vars = list(kmeans2_centers)[1:], \\\n",
    "       var_name = 'hour', value_name = 'load')\n",
    "kmeans2_centers['hour'] = kmeans2_centers['hour'].astype('float')\n",
    "kmeans2_centers['cluster'] = kmeans2_centers.cluster.apply(convert_clusters)\n",
    "kmeans2_centers['cluster'] = kmeans2_centers.cluster.astype('category')\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.lineplot(data=kmeans2_centers, x='hour', y='load', hue='cluster')\n",
    "f1.suptitle('Load 2 Cluster Centers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1000\n",
    "start = random.randint(0, len(train) - length)\n",
    "\n",
    "dcdata = train['load_1'].iloc[start:(start+length)]\n",
    "dcfreq = 24*7\n",
    "\n",
    "decomp1 = seasonal_decompose(dcdata, freq = dcfreq)\n",
    "\n",
    "decomp1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcfreq = 24*7\n",
    "decomp_test = seasonal_decompose(train['load_1'], freq = dcfreq)\n",
    "\n",
    "decomp_test.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Plots for Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2014-1':'2014-12'])\n",
    "f1.suptitle('Load 1: 2014')\n",
    "ax1.set(ylim = (15, 105))\n",
    "f1.savefig(fig_path + \"Load_1 ts 2014.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = train['2015-1':'2015-12'])\n",
    "f1.suptitle('Load 1: 2015')\n",
    "ax1.set(ylim = (15, 105))\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2014-1':'2014-12'])\n",
    "f1.suptitle('Load 2: 2014')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_2 ts 2014.png\", dpi = 300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = train['2015-1':'2015-12'])\n",
    "f1.suptitle('Load 2: 2015')\n",
    "ax1.set(ylim = (800, 3800))\n",
    "f1.savefig(fig_path + \"Load_1 ts 2015.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_data = load1_temp[(load1_temp.weekday_name == 'Wednesday') & (load1_temp.quarter == \"06:00 - 12:00\")]\n",
    "f1, ax1 = plt.subplots(figsize = (8, 8))\n",
    "sns.scatterplot(data=facet_data, x=\"temp\", y=\"load\", hue=\"hour\")\n",
    "f1.suptitle('Load 1: Wednesdays 06:00-12:00')\n",
    "f1.savefig(fig_path + \"Load_1 Wed Mid-Morning.png\", dpi=300)\n",
    "\n",
    "facet_data = load1_temp[(load1_temp.weekday_name == 'Sunday') & (load1_temp.quarter == \"18:00 - 00:00\")]\n",
    "f1, ax1 = plt.subplots(figsize = (8, 8))\n",
    "sns.scatterplot(data=facet_data, x=\"temp\", y=\"load\", hue=\"hour\")\n",
    "f1.suptitle('Load 1: Sundays 18:00-00:00')\n",
    "f1.savefig(fig_path + \"Load_1 Sunday Evening.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_data = load2_temp[(load2_temp.weekday_name == 'Wednesday') & (load2_temp.quarter == \"06:00 - 12:00\")]\n",
    "facet_data = facet_data['2014-08-10':'2015-06-25']\n",
    "f1, ax1 = plt.subplots(figsize = (8, 8))\n",
    "sns.lineplot(data=facet_data, x=\"temp\", y=\"load\", hue=\"hour\", sort=False)\n",
    "# sns.scatterplot(data=facet_data, x=\"temp\", y=\"load\", hue=\"hour\")\n",
    "f1.suptitle('Load 2: Wednesdays 06:00-12:00')\n",
    "f1.savefig(fig_path + \"Load_2 Wed Mid-Morning.png\", dpi=300)\n",
    "\n",
    "facet_data = load2_temp[(load2_temp.weekday_name == 'Sunday') & (load2_temp.quarter == \"18:00 - 00:00\")]\n",
    "facet_data = facet_data['2014-08-10':'2015-06-25']\n",
    "f1, ax1 = plt.subplots(figsize = (8, 8))\n",
    "sns.lineplot(data=facet_data, x=\"temp\", y=\"load\", hue=\"hour\", sort=False)\n",
    "# sns.scatterplot(data=facet_data, x=\"temp\", y=\"load\", hue=\"hour\")\n",
    "f1.suptitle('Load 2: Sundays 18:00-00:00')\n",
    "f1.savefig(fig_path + \"Load_2 Sunday Evening.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "sns.lineplot(data = load2[(load2['weekday_name'] == 'Wednesday') & (load2['hour'] == 18)]['2014-08-10':'2015-06-25'], \\\n",
    "                x = 'temp', y = 'load', sort=False)\n",
    "f1.suptitle('Load 2: Wednesdays 6pm, 08/10/2014 - 06/25/2015')\n",
    "f1.savefig(fig_path + \"Load_2 load vs temp Wed 6pm.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the work I completed after the first 8 hours. I definitely went a bit overboard, but it was out of my own interest and for my own benefit as a way to get some more practice in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spline regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_splines(train, predict):\n",
    "    \n",
    "    load1_mods = fit_models(train, 'load_1')\n",
    "    load2_mods = fit_models(train, 'load_2')\n",
    "    \n",
    "    result = predict_splines_grid(predict, load1_mods, 'load1_pred')\n",
    "    result = predict_splines_grid(result, load2_mods, 'load2_pred')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fit_models(df, load_num):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in range(0,7):\n",
    "\n",
    "        curr_models = []\n",
    "\n",
    "        for j in range(0,24):\n",
    "            curr_data = df[(df.weekday == i) & (df.hour == j)]\n",
    "            curr_X = curr_data.temp\n",
    "            curr_y = curr_data[load_num]\n",
    "\n",
    "            curr_mod = Earth()\n",
    "            curr_mod.fit(curr_X, curr_y)\n",
    "\n",
    "            curr_models.append(curr_mod)\n",
    "\n",
    "        result.append(curr_models)\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def predict_splines_grid(df, mod_array, col_name):\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,7):\n",
    "        for j in range(0,24):\n",
    "\n",
    "            curr_data = df[(df.weekday == i) & (df.hour == j)]\n",
    "            curr_X = curr_data.temp\n",
    "\n",
    "            curr_mod = mod_array[i][j]\n",
    "\n",
    "            curr_data = curr_data.assign(curr_pred = curr_mod.predict(curr_X))\n",
    "            \n",
    "            curr_data = curr_data.rename(columns = {'curr_pred':col_name})\n",
    "        \n",
    "            result = pd.concat([result, curr_data])\n",
    "                \n",
    "    return result\n",
    "\n",
    "\n",
    "def MAPE(actual, pred):\n",
    "        return sum(abs((actual - pred) / pred)) * 100 / len(actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsplines_validate = regression_splines(train, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load1_val_MAPE = MAPE(rsplines_validate.load_1, rsplines_validate.load1_pred)\n",
    "load2_val_MAPE = MAPE(rsplines_validate.load_2, rsplines_validate.load2_pred)\n",
    "\n",
    "print load1_val_MAPE\n",
    "print load2_val_MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2016-3-01'\n",
    "end = '2016-04-07'\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = rsplines_validate[start:end], label='Actual')\n",
    "sns.lineplot(x = 'datetime', y = 'load1_pred', data = rsplines_validate[start:end], color = 'red', label='Predicted')\n",
    "ax1.lines[1].set_linestyle(\"--\")\n",
    "ax1.legend(loc=1)\n",
    "f1.suptitle('Load 1: Sample Validation Set Predictions (MAPE = ' + str(round(load1_val_MAPE,2)) + \"%)\")\n",
    "f1.savefig(fig_path + 'Load_1 validation sample.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2016-3-01'\n",
    "end = '2016-04-07'\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = rsplines_validate[start:end], label='Actual')\n",
    "sns.lineplot(x = 'datetime', y = 'load2_pred', data = rsplines_validate[start:end], color = 'red', label='Predicted')\n",
    "# ax1.lines[1].set_linestyle(\"--\")\n",
    "ax1.legend(loc=1)\n",
    "f1.suptitle('Load 2: Sample Validation Set Predictions (MAPE = ' + str(round(load2_val_MAPE,2)) + \"%)\")\n",
    "f1.savefig(fig_path + 'Load_2 validation sample.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Adaptive Regression Splines - py-earth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the best package I could find for a MARS implementation, but unfortunately it does not support categorical predictors, so it couldn't be used to generate an accurate forecast in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train[['temp', 'hour', 'weekday']]\n",
    "# y = train['load_1']\n",
    "\n",
    "# model = Earth()\n",
    "# model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model.trace()\n",
    "# print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_test = load1.assign(pred = model.predict(X))\n",
    "\n",
    "# f1, ax1 = plt.subplots(figsize=(14, 8))\n",
    "# sns.lineplot(data = model_test['2014-01-01':'2014-01-21'], x = 'datetime', y = 'load')\n",
    "# sns.lineplot(data = model_test['2014-01-01':'2014-01-21'], x = 'datetime', y = 'pred', color='r')\n",
    "# f1.suptitle('Load 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set & Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.concat([train, validate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsplines_test = regression_splines(train_full, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_test_MAPE1 = MAPE(rsplines_test.load_1, rsplines_test.load1_pred)\n",
    "rs_test_MAPE2 = MAPE(rsplines_test.load_2, rsplines_test.load2_pred)\n",
    "\n",
    "print rs_test_MAPE1\n",
    "print rs_test_MAPE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2017-06-01'\n",
    "end = '2017-07-01'\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = rsplines_test[start:end], label='Actual')\n",
    "sns.lineplot(x = 'datetime', y = 'load1_pred', data = rsplines_test[start:end], color = 'red', label='Predicted')\n",
    "ax1.lines[1].set_linestyle(\"--\")\n",
    "ax1.legend(loc=1)\n",
    "f1.suptitle('Load 1: Test Set Sample Predictions (MAPE = ' + str(round(rs_test_MAPE1,2)) + \"%)\")\n",
    "f1.savefig(fig_path + 'Load_1 Test_set sample.png', dpi=300)\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_2', data = rsplines_test[start:end], label='Actual')\n",
    "sns.lineplot(x = 'datetime', y = 'load2_pred', data = rsplines_test[start:end], color = 'red', label='Predicted')\n",
    "ax1.lines[1].set_linestyle(\"--\")\n",
    "ax1.legend(loc=1)\n",
    "f1.suptitle('Load 2: Test Set Sample Predictions (MAPE = ' + str(round(rs_test_MAPE2,2)) + \"%)\")\n",
    "f1.savefig(fig_path + 'Load_2 Test_set sample.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving-Window / Rolling Day-Ahead Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This code may not be functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_ahead(df, start_date):\n",
    "    \n",
    "    # Pull out data for which predictions should be generated\n",
    "    pred_data = df[start_date:]\n",
    "    \n",
    "    # Series for storing results\n",
    "    load1_preds = pd.Series()\n",
    "    load2_preds = pd.Series()\n",
    "    \n",
    "    curr_data = pd.DataFrame()\n",
    "    curr_date = None\n",
    "    \n",
    "    # Iterate through observations\n",
    "    for index, row in pred_data.iterrows():\n",
    "        \n",
    "        # Select appropriate data before that observation\n",
    "        if row.date != curr_date:\n",
    "            curr_data = df[df.date < row.date]\n",
    "            curr_date = row.date\n",
    "        \n",
    "        train_data = curr_data[(curr_data.hour == row.hour) & (curr_data.weekday == row.weekday)]\n",
    "        \n",
    "        # Generate prediction for current observation\n",
    "        load1, load2 = make_preds(train_data, row)\n",
    "        \n",
    "        # Add predictions to series\n",
    "        load1_preds = load1_preds.append(pd.Series([load1]))\n",
    "        load2_preds = load2_preds.append(pd.Series([load2]))\n",
    "    \n",
    "    # Change prediction indices\n",
    "    load1_preds.index = pred_data.index\n",
    "    load2_preds.index = pred_data.index\n",
    "    \n",
    "    # Attach predictions to data frame\n",
    "    result = pred_data.assign(load1_pred = load1_preds)\n",
    "    result = result.assign(load2_pred = load2_preds)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day_ahead_test = day_ahead(data, '2018-09-01')\n",
    "# day_ahead_test = day_ahead_window(data, datetime.timedelta(days=21), '2018-09-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_MAPE1 = MAPE(day_ahead_test.load_1, day_ahead_test.load1_pred)\n",
    "rolling_MAPE2 = MAPE(day_ahead_test.load_2, day_ahead_test.load2_pred)\n",
    "\n",
    "print rolling_MAPE1\n",
    "print rolling_MAPE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_ahead_window(df, window_size, start_date):\n",
    "    \n",
    "    # Pull out data for which predictions should be generated\n",
    "    pred_data = df[start_date:]\n",
    "    \n",
    "    # Initialize Results Data Frame\n",
    "    result = pd.DataFrame()\n",
    "    \n",
    "    # Store data in the cutoff window\n",
    "    stored_data = None\n",
    "    stored_cutoff = datetime.date(1000, 1, 1)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    # Iterate through observations\n",
    "    for index, row in pred_data.iterrows():\n",
    "        \n",
    "        print i\n",
    "\n",
    "        # Calculate datetime of current row\n",
    "        curr_date = datetime.datetime.strptime(str(row.datetime), '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Check if current row is more than 1 week ahead of stored data\n",
    "        if (curr_date.date() - stored_cutoff) > datetime.timedelta(weeks=1):\n",
    "            \n",
    "            # Update stored data\n",
    "            stored_data = update_window(df, curr_date, window_size)\n",
    "    \n",
    "            # Update cutoff date\n",
    "            stored_cutoff = curr_date.date()\n",
    "            \n",
    "            # Train models\n",
    "            load1_mods = fit_models(stored_data, 'load_1')\n",
    "            load2_mods = fit_models(stored_data, 'load_2')\n",
    "            \n",
    "            # Make predictions\n",
    "            l1, l2 = make_preds(pred_data.loc[[index]], load1_mods, load2_mods)\n",
    "            \n",
    "            # Add predictions to row\n",
    "            curr_pred = pred_data.loc[[index]]\n",
    "            curr_pred = curr_pred.assign(load1_pred = l1)\n",
    "            curr_pred = curr_pred.assign(load2_pred = l2)     \n",
    "        \n",
    "        # Concatenate results\n",
    "        result = pd.concat([result, curr_pred])\n",
    "        \n",
    "        if i==5:\n",
    "            print result\n",
    "            print blabla\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def make_preds(row, load1_mods, load2_mods):\n",
    "    \n",
    "    # Pull x and y data\n",
    "    X = row.temp\n",
    "    y1 = row.load_1\n",
    "    y2 = row.load_2\n",
    "    \n",
    "    # Make predictions\n",
    "    mod1 = load1_mods[row.weekday.item()][row.hour.item()]\n",
    "    l1 = mod1.predict(row.temp)\n",
    "    \n",
    "    mod2 = load2_mods[row.weekday.item()][row.hour.item()]\n",
    "    l2 = mod2.predict(row.temp)\n",
    "    \n",
    "    return float(l1), float(l2)\n",
    "\n",
    "\n",
    "def update_window(df, date, window_size):\n",
    "\n",
    "    # Get weekday number of current date\n",
    "    wday = date.weekday()\n",
    "    \n",
    "    # Find date of previous Sunday\n",
    "    sun = date - datetime.timedelta(days = wday)\n",
    "    sun = sun.date()\n",
    "    \n",
    "    # Subtract window_size\n",
    "    start = sun - window_size\n",
    "    \n",
    "    # Slice data\n",
    "    result = df[(df.date >= start) & (df.date <= sun)]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def day_ahead_window(df, window_size, start_date):\n",
    "    \n",
    "#     # Pull out data for which predictions should be generated\n",
    "#     pred_data = df[start_date:]\n",
    "    \n",
    "#     # Series for storing results\n",
    "#     load1_preds = pd.Series()\n",
    "#     load2_preds = pd.Series()\n",
    "    \n",
    "#     # Iterate through observations\n",
    "#     for index, row in pred_data.iterrows():\n",
    "\n",
    "#         # Calculate datetime of current row\n",
    "#         curr_date = datetime.datetime.strptime(str(row.datetime), '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "#         # Calculate cut-off datetime for moving window\n",
    "#         cutoff =  curr_date - window_size\n",
    "        \n",
    "#         # Get data between cutoff date and 24 hours before current row\n",
    "#         train_data = df[(df.datetime >= cutoff) & (df.datetime < curr_date)]\n",
    "        \n",
    "#         # Generate prediction for current observation\n",
    "#         load1, load2 = make_preds(train_data, row)\n",
    "        \n",
    "#         # Add predictions to series\n",
    "#         load1_preds = load1_preds.append(pd.Series([load1]))\n",
    "#         load2_preds = load2_preds.append(pd.Series([load2]))\n",
    "    \n",
    "#     # Change prediction indices\n",
    "#     load1_preds.index = pred_data.index\n",
    "#     load2_preds.index = pred_data.index\n",
    "    \n",
    "#     # Attach predictions to data frame\n",
    "#     result = pred_data.assign(load1_pred = load1_preds)\n",
    "#     result = result.assign(load2_pred = load2_preds)\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_validate = day_ahead_window(validate, datetime.timedelta(days=28), '2016-03-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_eval_MAPE = MAPE(window_validate.load_1, window_validate.load1_pred)\n",
    "print da1_eval_MAPE\n",
    "\n",
    "da2_eval_MAPE = MAPE(window_validate.load_2, window_validate.load2_pred)\n",
    "print da2_eval_MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2016-3-01'\n",
    "end = '2016-04-07'\n",
    "\n",
    "f1, ax1 = plt.subplots(figsize = (14,8))\n",
    "sns.lineplot(x = 'datetime', y = 'load_1', data = window_validate[start:end], label='Actual')\n",
    "sns.lineplot(x = 'datetime', y = 'load1_pred', data = window_validate[start:end], color = 'red', label='Predicted')\n",
    "ax1.lines[1].set_linestyle(\"--\")\n",
    "ax1.legend(loc=1)\n",
    "f1.suptitle('Load 1: Sample Sliding-Window Predictions (MAPE = ' + str(round(load1_val_MAPE,2)) + \"%)\")\n",
    "# f1.savefig(fig_path + 'Load_1 validation sample.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
